{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Mdp2TpBh96Y"
   },
   "source": [
    "## Import TensorFlow and other libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7l3nqdWVF-kC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from collections import Counter\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib.metadata import version \n",
    "version('tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WORKING_MAC = True\n",
    "if WORKING_MAC:\n",
    "    loc_file_path = 'mac_file_path.csv'\n",
    "else:\n",
    "    loc_file_path = 'file_path.csv'\n",
    "\n",
    "random_state = 1234\n",
    "\n",
    "str_back = 'background'\n",
    "str_embeddings = 'Embeddings'\n",
    "str_fore = 'foreground'\n",
    "str_fold = 'fold'\n",
    "str_filename = 'filename'\n",
    "str_target = 'target'\n",
    "\n",
    "#############  Tensorflow Random State  #########################\n",
    "tf.keras.utils.set_random_seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06CWkBV5v3gr"
   },
   "outputs": [],
   "source": [
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvrncrMyUl_v",
    "outputId": "71f47631-09cf-4b5f-ee70-6b9d996e5205"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import re\n",
    "\n",
    "def extract_all_zips():\n",
    "  if WORKING_MAC:\n",
    "    loc_file_folder = '/Users/wyd2hu/Documents/SA39/ForegroundSpeech/dataverse_files'\n",
    "  else:\n",
    "     loc_file_folder = 'C:/Users/wyd2hu/OneDrive - University of Virginia/Katha/dataverse_files/'\n",
    "\n",
    "  data_list_df = []\n",
    "\n",
    "  for outer_folder in os.listdir(loc_file_folder):\n",
    "    if 'DS_Store' not in outer_folder:\n",
    "      for wav_file in os.listdir(os.path.join(loc_file_folder, outer_folder)):\n",
    "          if wav_file.endswith('.wav'):\n",
    "            data_list_df.append([os.path.join(loc_file_folder, outer_folder, wav_file),\n",
    "                                1 if str_fore in outer_folder else 0,\n",
    "                                int(re.findall(r'\\d+', outer_folder)[0])])\n",
    "  \n",
    "  df_path = pd.DataFrame(data = data_list_df, columns = [str_filename, str_target, 'Dataset Fold'])\n",
    "\n",
    "  \n",
    "  df_path.to_csv(loc_file_path, index=False)\n",
    "  print(df_path)\n",
    "  print(df_path.shape)\n",
    "\n",
    "extract_all_zips()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer the learning from YAMNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for loading audio files and making sure the sample rate is correct.\n",
    "# applies the embedding extraction model to a wav data\n",
    "def extract_embedding(wav_data, label, fold):\n",
    "  ''' run YAMNet to extract embedding from the wav data '''\n",
    "  scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
    "  num_embeddings = tf.shape(embeddings)[0]\n",
    "  return (embeddings,\n",
    "            tf.repeat(label, num_embeddings),\n",
    "            tf.repeat(fold, num_embeddings))\n",
    "\n",
    "def load_wav_for_map(filename, label, fold):\n",
    "  return load_wav_16k_mono(filename), label, fold\n",
    "\n",
    "@tf.function\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "\n",
    "def extract_embedding_for_all_data(wav_data, label, filename):\n",
    "  ''' run YAMNet to extract embedding from the wav data '''\n",
    "  scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
    "  num_embeddings = tf.shape(embeddings)[0]\n",
    "  return (embeddings,\n",
    "            tf.repeat(label, num_embeddings),\n",
    "            tf.repeat(filename, num_embeddings))\n",
    "\n",
    "def load_wav_for_map_for_all_data(filename, label):\n",
    "  return load_wav_16k_mono(filename), label, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_level_prediction(list_actual_class, predicted_proba):\n",
    "  zip_true_predicted = list(zip(list_actual_class, predicted_proba))\n",
    "\n",
    "  list_y_true = []\n",
    "  list_y_pred = []\n",
    "\n",
    "  for first_frame, second_frame in zip(zip_true_predicted[::2], zip_true_predicted[1::2]):\n",
    "\n",
    "    if first_frame[0] != second_frame[0]:\n",
    "      print('\\n\\n\\n\\nSevere problem\\n\\n\\n\\n')\n",
    "    else:\n",
    "      list_y_true.append(first_frame[0])\n",
    "\n",
    "      clip_prob = np.array([first_frame[1], second_frame[1]])\n",
    "      class_in_frames = clip_prob.argmax(axis=-1)\n",
    "      if len(np.unique(class_in_frames)) == 1: # means the predicted class is same in each frame:\n",
    "        list_y_pred.append(class_in_frames[0])\n",
    "      else: # means the predicted class differs between the first and second frame of 1 second audio clip\n",
    "        list_y_pred.append(np.argmax(np.sum(clip_prob, axis=0)))\n",
    "\n",
    "  return list_y_true, list_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_g_aud_loc():\n",
    "  loc_g_aud = 'C:/Users/wyd2hu/S2He/AudData/Google AudioSet_Balanced_Train/Speech//10_seconds'\n",
    "  list_loc_g_aud_files = loc_g_aud +'//'+ pd.Series(os.listdir(loc_g_aud))\n",
    "  df_g_aud_loc = pd.DataFrame({str_filename: list_loc_g_aud_files,\n",
    "                               str_target: np.repeat(1, len(list_loc_g_aud_files))})\n",
    "  df_g_aud_loc.to_excel('google_aud_speech_class_data.xlsx', index=False)\n",
    "  print(df_g_aud_loc)\n",
    "\n",
    "get_df_g_aud_loc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = pd.read_csv(loc_file_path)\n",
    "\n",
    "df_path = shuffle(df_path, random_state = random_state)\n",
    "df_path.reset_index(inplace=True, drop=True)\n",
    "\n",
    "list_all_files = df_path[str_filename].tolist()\n",
    "list_all_labels = df_path[str_target].tolist()\n",
    "\n",
    "df_g_aud_loc = pd.read_excel('google_aud_speech_class_data.xlsx')\n",
    "list_all_files.extend(df_g_aud_loc[str_filename])\n",
    "list_all_labels.extend(df_g_aud_loc[str_target])\n",
    "\n",
    "main_ds_all_data = tf.data.Dataset.from_tensor_slices((list_all_files, list_all_labels))\n",
    "main_ds_all_data = main_ds_all_data.map(load_wav_for_map_for_all_data)\n",
    "main_ds_all_data = main_ds_all_data.map(extract_embedding_for_all_data).unbatch()\n",
    "\n",
    "df_embedding_all_data = pd.DataFrame(columns = [str_embeddings, str_target, str_filename])\n",
    "for emb, label, file_name in main_ds_all_data:\n",
    "  df_embedding_all_data.loc[-1] = [emb, label, file_name.numpy().decode()]\n",
    "  df_embedding_all_data.index += 1\n",
    "  df_embedding_all_data = df_embedding_all_data.sort_index()\n",
    "\n",
    "print(df_embedding_all_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training, Validation, and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedding_all_data = pd.read_pickle('embedd_dataverse_g_aud_balanced_trained.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_metrics = [keras.metrics.TruePositives(name='tp'),\n",
    "                keras.metrics.FalsePositives(name='fp'),\n",
    "                keras.metrics.TrueNegatives(name='tn'),\n",
    "                keras.metrics.FalseNegatives(name='fn'),\n",
    "                keras.metrics.F1Score(name='f1_score', threshold=0.5, average='macro'),\n",
    "                keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                keras.metrics.Precision(name='precision'),\n",
    "                keras.metrics.Recall(name='recall'),\n",
    "                keras.metrics.AUC(name='auc')]\n",
    "print('I am here')\n",
    "\n",
    "def train_val_test():\n",
    "  global all_predicted_proba, all_list_actual_class, df_embedding_all_data, METRICS\n",
    "  all_predicted_proba = []\n",
    "  all_list_actual_class = []\n",
    "\n",
    "  batch_size = 32\n",
    "  n_epoch = 10\n",
    "  \n",
    "  print('I am here')\n",
    "\n",
    "  df_path = pd.read_csv(loc_file_path)\n",
    "  df_path = shuffle(df_path, random_state = random_state)\n",
    "  df_path.reset_index(inplace=True, drop=True)\n",
    "  print('I am here')\n",
    "  \n",
    "  my_classes = set(df_path[str_target])\n",
    "  validation_ratio = 0.10\n",
    "  test_ratio = 0.10\n",
    "\n",
    "  for batch_size in [32]:\n",
    "    print('I am here')\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=25, shuffle=True, random_state = random_state)\n",
    "\n",
    "    for ith_fold, (train_index, test_index) in enumerate(skf.split(df_path[str_filename], df_path[str_target])):\n",
    "\n",
    "      # Keeping the filenames in x_train since just based on the filenames, the embedddings will be retrieved.\n",
    "      x_train = df_path.iloc[train_index][str_filename].tolist()\n",
    "      y_train = df_path.iloc[train_index][str_target].tolist()\n",
    "\n",
    "      x_test = df_path.iloc[test_index][str_filename].tolist()\n",
    "      y_test = df_path.iloc[test_index][str_target].tolist()\n",
    "\n",
    "      x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size = test_ratio / (test_ratio + validation_ratio),\n",
    "                                                      shuffle=True, stratify = y_test, random_state = random_state)\n",
    "\n",
    "      df_temp_train = pd.DataFrame({str_filename: x_train, str_target: y_train})\n",
    "    #   df_original_class_0 = df_temp_train[df_temp_train[str_target] == 0].copy()\n",
    "    #   df_train_class_1 = df_temp_train[df_temp_train[str_target] == 1].copy()\n",
    "\n",
    "    #   df_g_aud_loc = pd.read_excel('google_aud_speech_class_data.xlsx')\n",
    "    #   df_train_class_0 = df_original_class_0.iloc[:(df_train_class_1.shape[0] + int((int(10/0.48) * df_g_aud_loc.shape[0]) / 2))].copy()\n",
    "    #   df_temp_train = pd.concat([df_train_class_1, df_train_class_0])\n",
    "\n",
    "    #   df_temp_train = pd.concat([df_temp_train, df_g_aud_loc])\n",
    "      df_temp_train[str_fold] = np.repeat(1, df_temp_train.shape[0]) # 1 is used (randomly) to denote the train fold everywhere\n",
    "\n",
    "      df_temp_val = pd.DataFrame({str_filename: x_val, str_target: y_val})\n",
    "      df_temp_val[str_fold] = np.repeat(2, df_temp_val.shape[0])\n",
    "\n",
    "      df_temp_test = pd.DataFrame({str_filename: x_test, str_target: y_test})\n",
    "      df_temp_test[str_fold] = np.repeat(3, df_temp_test.shape[0])\n",
    "\n",
    "      pd_data = pd.concat([df_temp_train, df_temp_val, df_temp_test])\n",
    "\n",
    "      for train_fold, val_fold, test_fold in ((1, 2, 3), (1, 3, 2)):\n",
    "        print(train_fold, val_fold, test_fold)\n",
    "        filenames = pd_data[str_filename]\n",
    "        targets = pd_data[str_target]\n",
    "        folds = pd_data[str_fold]\n",
    "\n",
    "        # print(df_embedding_all_data[str_filename].isin(pd_data[pd_data[str_fold] == train_fold][str_filename].tolist()))\n",
    "        train_ds = df_embedding_all_data[df_embedding_all_data[str_filename].isin(pd_data[pd_data[str_fold] == train_fold][str_filename])].copy()\n",
    "        # rows_organized_train = []\n",
    "        # for row_class_1, row_class_0 in zip(train_ds[train_ds[str_target] == 1].itertuples(index = False),\n",
    "        #                                     train_ds[train_ds[str_target] == 0].itertuples(index = False)):\n",
    "        #     rows_organized_train.append(row_class_1)\n",
    "        #     rows_organized_train.append(row_class_0)\n",
    "        \n",
    "        train_ds = shuffle(train_ds, random_state = random_state)\n",
    "        train_ds.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        neg, pos = np.bincount(train_ds[str_target])\n",
    "        \n",
    "        total = neg + pos\n",
    "        weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "        weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "        class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "\n",
    "        # train_ds = pd.DataFrame(data = rows_organized_train,\n",
    "        #                         columns=train_ds.columns.tolist())\n",
    "        print('\\n\\nTrain', train_ds[train_ds[str_target] == 1].shape[0], train_ds[train_ds[str_target] == 0].shape[0])\n",
    "\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((train_ds[str_embeddings].tolist(), train_ds[str_target].tolist()))\n",
    "\n",
    "        val_ds = df_embedding_all_data[df_embedding_all_data[str_filename].isin(pd_data[pd_data[str_fold] == val_fold][str_filename])].copy()\n",
    "        val_ds = tf.data.Dataset.from_tensor_slices((val_ds[str_embeddings].tolist(), val_ds[str_target].tolist()))\n",
    "\n",
    "        test_ds = df_embedding_all_data[df_embedding_all_data[str_filename].isin(pd_data[pd_data[str_fold] == test_fold][str_filename])].copy()\n",
    "        test_ds = tf.data.Dataset.from_tensor_slices((test_ds[str_embeddings].tolist(), test_ds[str_target].tolist()))\n",
    "\n",
    "        clip_level_list_actual_class =  list(map(lambda x: x[1].numpy(), test_ds))\n",
    "        print(len(clip_level_list_actual_class))\n",
    "        # print(clip_level_list_actual_class)\n",
    "\n",
    "        print('Hey, I am here 1')\n",
    "\n",
    "        train_ds = train_ds.cache().shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        val_ds = val_ds.cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        test_ds = test_ds.cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        print('Hey, I am here 2')\n",
    "\n",
    "        keras_yamnet_model = keras.Sequential([hub.KerasLayer(yamnet_model)])\n",
    "        leaky_relu = keras.layers.LeakyReLU(alpha=0.1)\n",
    "\n",
    "        print(np.log([pos/neg]))\n",
    "\n",
    "        model_B_on_A = keras.models.Sequential(keras_yamnet_model.layers[:-4])\n",
    "        model_B_on_A.add(keras.layers.Dense(2048, activation = leaky_relu))\n",
    "        model_B_on_A.add(keras.layers.Dense(1024, activation = leaky_relu))\n",
    "        model_B_on_A.add(keras.layers.Dense(512, activation = leaky_relu))\n",
    "        model_B_on_A.add(keras.layers.Dense(len(my_classes)-1, activation ='sigmoid', bias_initializer=  tf.keras.initializers.Constant(np.log([pos/neg]))))\n",
    "\n",
    "        for layer in model_B_on_A.layers[:-4]:\n",
    "          layer.trainable = False\n",
    "\n",
    "        print('Hey, I am here 3')\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "        model_B_on_A.compile(loss=keras.losses.BinaryCrossentropy(), optimizer=optimizer,\n",
    "                            metrics= list_metrics)\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        history = model_B_on_A.fit(train_ds, epochs=n_epoch,\n",
    "                                  validation_data=val_ds,\n",
    "                                  callbacks = callback,\n",
    "                                  class_weight=class_weight,\n",
    "                                  verbose=1)\n",
    "        \n",
    "        dict_predict_test = model_B_on_A.evaluate(test_ds, return_dict=True)\n",
    "        specificity = dict_predict_test.get('tn')/(dict_predict_test.get('tn') + dict_predict_test.get('fp'))\n",
    "\n",
    "        print('\\n\\n\\n Without retrain all layers ')\n",
    "        print('Test Performance\\n\\n', batch_size, ith_fold, dict_predict_test.get('precision'), dict_predict_test.get('recall'),\n",
    "               specificity, dict_predict_test.get('accuracy'), dict_predict_test.get('auc'), (specificity + dict_predict_test.get('recall'))/2, '\\n\\n\\n')\n",
    "        print('Hey, retraining :)')\n",
    "\n",
    "        for layer in model_B_on_A.layers[:-4]:\n",
    "          layer.trainable = True\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999) # the default lr is 1e-3\n",
    "        model_B_on_A.compile(loss=keras.losses.BinaryCrossentropy(), optimizer=optimizer,\n",
    "                             metrics=list_metrics)\n",
    "        history = model_B_on_A.fit(train_ds, epochs=n_epoch,\n",
    "                                   validation_data=val_ds,\n",
    "                                   class_weight=class_weight,\n",
    "                                   callbacks = callback, verbose=1)\n",
    "\n",
    "        # predicted_proba = model_B_on_A.predict(test_ds)\n",
    "        # list_actual_class, list_predict_class = get_clip_level_prediction(clip_level_list_actual_class, predicted_proba)\n",
    "        # precision = precision_score(y_true=list_actual_class, y_pred=list_predict_class)\n",
    "        # recall = recall_score(y_true=list_actual_class, y_pred=list_predict_class)\n",
    "        # specificity = recall_score(y_true=list_actual_class, y_pred=list_predict_class, pos_label=0)\n",
    "        # f1 = f1_score(y_true=list_actual_class, y_pred=list_predict_class, average='macro')\n",
    "        # acc = accuracy_score(y_true=list_actual_class, y_pred=list_predict_class)\n",
    "\n",
    "        # all_predicted_proba.extend(list_predict_class)\n",
    "        # all_list_actual_class.extend(list_actual_class)\n",
    "\n",
    "        dict_predict_test = model_B_on_A.evaluate(test_ds, return_dict=True)\n",
    "\n",
    "        print('\\n\\n\\n After retrain all layers ')\n",
    "        print('Test Performance\\n\\n', batch_size, ith_fold, dict_predict_test.get('precision'), dict_predict_test.get('recall'),\n",
    "               specificity, dict_predict_test.get('accuracy'), dict_predict_test.get('auc'), (specificity + dict_predict_test.get('recall'))/2, '\\n\\n\\n')\n",
    "\n",
    "train_val_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standalone usage:\n",
    "initializer = RandomNormal(mean=0.0, stddev=1.0)\n",
    "values = initializer(shape=(2, 2))\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.data.Dataset.from_tensor_slices([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_predict_class = all_predicted_proba\n",
    "list_actual_class = all_list_actual_class\n",
    "precision = precision_score(y_true=list_actual_class, y_pred=list_predict_class)\n",
    "recall = recall_score(y_true=list_actual_class, y_pred=list_predict_class)\n",
    "specificity = recall_score(y_true=list_actual_class, y_pred=list_predict_class, pos_label=0)\n",
    "f1 = f1_score(y_true=list_actual_class, y_pred=list_predict_class, average='macro')\n",
    "acc = accuracy_score(y_true=list_actual_class, y_pred=list_predict_class)\n",
    "\n",
    "print(precision, recall, specificity, f1, acc, (recall + specificity)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Google Audio Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_class_label = pd.read_csv(\"C:/Users/wyd2hu/Downloads/archive/class_labels_indices.csv\")\n",
    "df_file_name = pd.read_csv(\"C:/Users/wyd2hu/Downloads/archive/train.csv\")\n",
    "loc_root_wav = 'C:/Users/wyd2hu/Downloads/archive/train_wav/'\n",
    "\n",
    "list_file_mid = []\n",
    "list_class_names = []\n",
    "\n",
    "for index, row_class in df_class_label.iterrows():\n",
    "    if 'speech' in row_class['display_name'].lower() and 'noise' not in row_class['display_name'].lower():\n",
    "        list_file_mid.append(row_class['mid'])\n",
    "        list_class_names.append(row_class['display_name'])\n",
    "\n",
    "def has_mid_name(value_list):\n",
    "  return any(value in value_list for value in list_file_mid)\n",
    "\n",
    "print(list_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioset_download import Downloader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# list_class_names.append('Narration, monologue')\n",
    "# print(list_class_names)\n",
    "list_class_names = ['Speech']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "d = Downloader(root_path='C:/Users/wyd2hu/S2He/AudData/Google AudioSet_Balanced_Train/', labels=list_class_names, n_jobs=13, download_type='balanced_train', copy_and_replicate=False)\n",
    "d.download(format = 'wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_name['positive_labels'] = df_file_name['positive_labels'].apply(lambda x: x.split(','))\n",
    "filtered_df = df_file_name[df_file_name['positive_labels'].apply(has_mid_name)]\n",
    "\n",
    "for ytid in filtered_df['YTID']:\n",
    "    loc_wav = loc_root_wav + ytid + '.wav'\n",
    "    audio_data, sample_rate = librosa.load(loc_wav)\n",
    "    duration = librosa.get_duration(y=audio_data, sr=sample_rate)\n",
    "    print(duration)\n",
    "    try:\n",
    "        extract_features(loc_wav, True)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 Tuning Short Google Audio Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "\n",
    "def create_spectram_plot(loc_data_folder, loc_fig_folder):\n",
    "  for class_folder in os.listdir(loc_data_folder):\n",
    "    if 'Class_0' in class_folder:\n",
    "      n_file_processing = 0\n",
    "      n_class_instance = 0\n",
    "      if not os.path.isdir(os.path.join(loc_fig_folder, class_folder)):\n",
    "        os.mkdir(os.path.join(loc_fig_folder, class_folder))\n",
    "      for file_name in os.listdir(os.path.join(loc_data_folder, class_folder)):\n",
    "        if file_name.endswith('.wav') and (not os.path.exists(os.path.join(loc_fig_folder, class_folder, file_name.replace('wav', 'png')))) and (librosa.get_duration(filename=os.path.join(loc_data_folder, class_folder, file_name)) > 0) :\n",
    "          n_class_instance += 1\n",
    "          signal, sr = librosa.load(os.path.join(loc_data_folder, class_folder, file_name))\n",
    "          stft = librosa.stft(signal)\n",
    "\n",
    "          fig, ax = plt.subplots()\n",
    "          img = librosa.display.specshow(librosa.amplitude_to_db(stft, ref=np.max), ax=ax)\n",
    "          fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "          fig.savefig(os.path.join(loc_fig_folder, class_folder, file_name.replace('wav', 'png')))\n",
    "          plt.close(fig)\n",
    "        \n",
    "        n_file_processing += 1\n",
    "        print(n_file_processing, n_class_instance, class_folder, os.path.basename(loc_data_folder))\n",
    "\n",
    "# create_spectram_plot(\"C:/Users/wyd2hu/S2He/AudData/ResNetPlay/Train_Speech\",\n",
    "#                      \"C:/Users/wyd2hu/S2He/AudData/ResNetPlay/Figure_Google_Aud\")\n",
    "# create_spectram_plot(\"C:/Users/wyd2hu/S2He/AudData/ResNetPlay/Test_Speech\",\n",
    "#                      \"C:/Users/wyd2hu/S2He/AudData/ResNetPlay/Figure_Google_Aud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "keras_ResNet_model = tf.keras.Sequential([hub.KerasLayer(ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "image_size = 150\n",
    "input_size = 150\n",
    "train_dir = \"C:/Users/wyd2hu/S2He/AudData/ResNetPlay/Figure_Google_Aud/\"\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import re\n",
    "\n",
    "df_train_dir = pd.DataFrame(columns = [str_filename, str_target])\n",
    "for class_folder in os.listdir(train_dir):\n",
    "  print(class_folder)\n",
    "  if 'Class' in class_folder: # find .ipynb_checkpoints in Google Colab. Thus, I had to set this condition\n",
    "    df_temp = pd.DataFrame({str_filename: [os.path.join(train_dir, class_folder, filename) for filename in os.listdir(os.path.join(train_dir, class_folder))],\n",
    "                            str_target: np.repeat(class_folder.strip(),\n",
    "                                                  len(os.listdir(os.path.join(train_dir, class_folder))))})\n",
    "    df_train_dir = pd.concat([df_train_dir, df_temp])\n",
    "\n",
    "df_train_dir = shuffle(df_train_dir, random_state=random_state)\n",
    "df_train_dir.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(df_train_dir)\n",
    "\n",
    "# Create generator with augmentation for training\n",
    "train_gen = ImageDataGenerator(samplewise_center=True,\n",
    "                               samplewise_std_normalization=True).flow_from_dataframe(\n",
    "                               dataframe=df_train_dir.head(int(df_train_dir.shape[0] * 0.8)),\n",
    "                               x_col = str_filename,\n",
    "                               y_col = str_target,\n",
    "                               directory=train_dir,\n",
    "                               target_size=(image_size, image_size),\n",
    "                               class_mode='binary',\n",
    "                               batch_size=16,\n",
    "                               shuffle=True)\n",
    "\n",
    "val_gen = ImageDataGenerator(samplewise_center=True,\n",
    "                               samplewise_std_normalization=True).flow_from_dataframe(\n",
    "                               dataframe=df_train_dir.iloc[int(0.8 * df_train_dir.shape[0]) : int(0.9 * df_train_dir.shape[0])],\n",
    "                               x_col = str_filename,\n",
    "                               y_col = str_target,\n",
    "                               directory=train_dir,\n",
    "                               target_size=(image_size, image_size),\n",
    "                               class_mode='binary',\n",
    "                               batch_size=16,\n",
    "                               shuffle=True)\n",
    "\n",
    "test_gen = ImageDataGenerator(samplewise_center=True,\n",
    "                               samplewise_std_normalization=True).flow_from_dataframe(\n",
    "                               dataframe=df_train_dir.tail(int(df_train_dir.shape[0] * 0.1)),\n",
    "                               x_col = str_filename,\n",
    "                               y_col = str_target,\n",
    "                               directory=train_dir,\n",
    "                               target_size=(image_size, image_size),\n",
    "                               class_mode='binary',\n",
    "                               batch_size=16,\n",
    "                               shuffle=True)\n",
    "\n",
    "classes = df_train_dir.head(int(df_train_dir.shape[0] * 0.8))[str_target].str.replace('Class_', '').astype(np.int16)\n",
    "print(classes)\n",
    "neg, pos = np.bincount(classes)\n",
    "        \n",
    "total = neg + pos\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "classes = dict((v, k) for k, v in train_gen.class_indices.items())\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_metrics = [keras.metrics.TruePositives(name='tp'),\n",
    "                keras.metrics.FalsePositives(name='fp'),\n",
    "                keras.metrics.TrueNegatives(name='tn'),\n",
    "                keras.metrics.FalseNegatives(name='fn'),\n",
    "                tfa.metrics.F1Score(name='f1_score', num_classes=1, threshold=0.5, average='macro'),\n",
    "                keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                keras.metrics.Precision(name='precision'),\n",
    "                keras.metrics.Recall(name='recall'),\n",
    "                keras.metrics.AUC(name='auc')]\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "\n",
    "keras_ResNet_model = tf.keras.Sequential([hub.KerasLayer(ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3)))])\n",
    "model_B_on_A = keras.models.Sequential(keras_ResNet_model.layers[:-1])\n",
    "\n",
    "model_B_on_A.add(keras.layers.Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model_B_on_A.add(keras.layers.Activation('relu'))\n",
    "model_B_on_A.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_B_on_A.add(keras.layers.Conv2D(32, (3, 3)))\n",
    "model_B_on_A.add(keras.layers.Activation('relu'))\n",
    "model_B_on_A.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_B_on_A.add(keras.layers.Conv2D(64, (3, 3)))\n",
    "model_B_on_A.add(keras.layers.Activation('relu'))\n",
    "model_B_on_A.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_B_on_A.add(keras.layers.Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model_B_on_A.add(keras.layers.Dense(64))\n",
    "model_B_on_A.add(keras.layers.Activation('relu'))\n",
    "model_B_on_A.add(keras.layers.Dropout(0.5))\n",
    "model_B_on_A.add(keras.layers.Dense(1))\n",
    "model_B_on_A.add(keras.layers.Activation('sigmoid'))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "  layer.trainable = False\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999) # the default lr is 1e-3\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model_B_on_A.compile(loss='binary_crossentropy',\n",
    "                     optimizer=optimizer,\n",
    "                     metrics=list_metrics)\n",
    "\n",
    "history = model_B_on_A.fit_generator(train_gen,\n",
    "                           epochs=5,\n",
    "                           validation_data=val_gen,\n",
    "                           callbacks = callback,\n",
    "                           class_weight=class_weight,\n",
    "                           verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_predict_test = model_B_on_A.evaluate(test_gen, return_dict=True)\n",
    "specificity = dict_predict_test.get('tn')/(dict_predict_test.get('tn') + dict_predict_test.get('fp'))\n",
    "\n",
    "print('\\n\\n\\n Without retrain all layers ')\n",
    "print('Test Performance\\n\\n', dict_predict_test.get('precision'), dict_predict_test.get('recall'),\n",
    "        specificity, dict_predict_test.get('accuracy'), dict_predict_test.get('auc'), (specificity + dict_predict_test.get('recall'))/2, '\\n\\n\\n')\n",
    "print('Hey, retraining :)')\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999) # the default lr is 1e-3\n",
    "model_B_on_A.compile(loss='binary_crossentropy',\n",
    "                     optimizer=optimizer,\n",
    "                     metrics=list_metrics)\n",
    "\n",
    "history = model_B_on_A.fit_generator(train_gen,\n",
    "                           epochs=20,\n",
    "                           validation_data=val_gen,\n",
    "                           callbacks = callback,\n",
    "                           class_weight=class_weight,\n",
    "                           verbose = 1)\n",
    "\n",
    "# predicted_proba = model_B_on_A.predict(test_ds)\n",
    "# list_actual_class, list_predict_class = get_clip_level_prediction(clip_level_list_actual_class, predicted_proba)\n",
    "# precision = precision_score(y_true=list_actual_class, y_pred=list_predict_class)\n",
    "# recall = recall_score(y_true=list_actual_class, y_pred=list_predict_class)\n",
    "# specificity = recall_score(y_true=list_actual_class, y_pred=list_predict_class, pos_label=0)\n",
    "# f1 = f1_score(y_true=list_actual_class, y_pred=list_predict_class, average='macro')\n",
    "# acc = accuracy_score(y_true=list_actual_class, y_pred=list_predict_class)\n",
    "\n",
    "# all_predicted_proba.extend(list_predict_class)\n",
    "# all_list_actual_class.extend(list_actual_class)\n",
    "\n",
    "dict_predict_test = model_B_on_A.evaluate(test_gen, return_dict=True)\n",
    "\n",
    "print('\\n\\n\\n After retrain all layers ')\n",
    "print('Test Performance\\n\\n',dict_predict_test.get('precision'), dict_predict_test.get('recall'),\n",
    "        specificity, dict_predict_test.get('accuracy'), dict_predict_test.get('auc'), (specificity + dict_predict_test.get('recall'))/2, '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.save('resnet_tuned_on_google_aud.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_predict_test = model_B_on_A.evaluate(test_gen, return_dict=True)\n",
    "\n",
    "print('\\n\\n\\n After retrain all layers ')\n",
    "print('Test Performance\\n\\n',dict_predict_test.get('precision'), dict_predict_test.get('recall'),\n",
    "        specificity, dict_predict_test.get('accuracy'), dict_predict_test.get('auc'), (specificity + dict_predict_test.get('recall'))/2, '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "assert tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 on DataVerse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "\n",
    "if WORKING_MAC:\n",
    "    loc_raw_dataverse_files = '/Users/wyd2hu/Documents/SA39/ForegroundSpeech/dataverse_files/'\n",
    "    loc_fig_dataverse = '/Users/wyd2hu/Documents/SA39/ForegroundSpeech/Only_Spectrogram_Figure_Dataverse/' \n",
    "    # '/Users/wyd2hu/Documents/SA39/ForegroundSpeech/Figure_Datverse/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_image(file_name):\n",
    "    n_row = 3\n",
    "    n_col = 2\n",
    "    fig, axs = plt.subplots(n_col, n_row, figsize=(20, 20))\n",
    "\n",
    "    signal, sr = librosa.load(file_name)\n",
    "    N_FFT = int(sr * 0.025)\n",
    "    HOP_LENGTH = int(sr * 0.0125)\n",
    "\n",
    "    stft = librosa.stft(signal, n_fft = N_FFT, hop_length = HOP_LENGTH)\n",
    "    \n",
    "    librosa.display.specshow(librosa.amplitude_to_db(stft, ref=np.max), \n",
    "                            y_axis='log', x_axis='time', ax=axs[0, 0])\n",
    "    librosa.display.specshow(librosa.feature.mfcc(S=stft, n_fft = N_FFT, hop_length = HOP_LENGTH), \n",
    "                            x_axis='time', y_axis='mel', ax=axs[0, 1])\n",
    "    librosa.display.specshow(librosa.feature.chroma_stft(S=stft, n_fft = N_FFT, hop_length = HOP_LENGTH), \n",
    "                            y_axis='chroma', x_axis='time', ax=axs[0, 2])\n",
    "    librosa.display.specshow(librosa.feature.chroma_cqt(y=signal, sr=sr),\n",
    "                            y_axis='chroma', x_axis='time', ax=axs[1, 0])\n",
    "    onset_env = librosa.onset.onset_strength(y = signal, sr=sr)\n",
    "    librosa.display.specshow(librosa.feature.tempogram(onset_envelope = onset_env, sr = sr, hop_length = HOP_LENGTH), \n",
    "                            y_axis='tempo', x_axis='time', cmap='magma', ax=axs[1, 1])\n",
    "    librosa.display.specshow(librosa.feature.fourier_tempogram(onset_envelope = onset_env, sr=sr, hop_length = HOP_LENGTH),\n",
    "                            x_axis='time', y_axis='fourier_tempo', cmap='magma',\n",
    "                            ax=axs[1, 2])\n",
    "    \n",
    "    for row in range(0, n_row):\n",
    "        for col in range(0, n_col):\n",
    "            axs[col][row].xaxis.label.set_visible(False)\n",
    "            axs[col][row].yaxis.label.set_visible(False)\n",
    "            axs[col][row].set_xticklabels([])\n",
    "            axs[col][row].set_yticklabels([])\n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_spectrogram(file_name):\n",
    "    n_row = 1\n",
    "    n_col = 1\n",
    "    fig, axs = plt.subplots(n_col, n_row, figsize=(20, 20))\n",
    "\n",
    "    signal, sr = librosa.load(file_name)\n",
    "    N_FFT = int(sr * 0.025)\n",
    "    HOP_LENGTH = int(sr * 0.0125)\n",
    "\n",
    "    stft = librosa.stft(signal, n_fft = N_FFT, hop_length = HOP_LENGTH)\n",
    "    \n",
    "    librosa.display.specshow(librosa.amplitude_to_db(stft, ref=np.max), \n",
    "                            y_axis='log', x_axis='time', ax=axs)\n",
    "    \n",
    "    axs.xaxis.label.set_visible(False)\n",
    "    axs.yaxis.label.set_visible(False)\n",
    "    axs.set_xticklabels([])\n",
    "    axs.set_yticklabels([])\n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_spectram_plot(loc_data_folder, loc_fig_folder):\n",
    "  n_file_processing = 0\n",
    "\n",
    "  for class_folder in sorted(os.listdir(loc_data_folder))[:3]:\n",
    "    if 'DS_Store' not in class_folder:\n",
    "      if not os.path.isdir(os.path.join(loc_fig_folder, class_folder)):\n",
    "        os.mkdir(os.path.join(loc_fig_folder, class_folder))\n",
    "\n",
    "      for file_name in sorted(os.listdir(os.path.join(loc_data_folder, class_folder))):\n",
    "        if file_name.endswith('.wav') and (not os.path.exists(os.path.join(loc_fig_folder, class_folder, file_name.replace('wav', 'png')))) and (librosa.get_duration(filename=os.path.join(loc_data_folder, class_folder, file_name)) > 0) :\n",
    "            fig = create_spectrogram(os.path.join(loc_data_folder, class_folder, file_name))\n",
    "            fig.savefig(os.path.join(loc_fig_folder, class_folder, file_name.replace('wav', 'png')))\n",
    "            plt.close(fig)\n",
    "\n",
    "        n_file_processing += 1\n",
    "        print(n_file_processing, class_folder, os.path.basename(loc_data_folder))\n",
    "\n",
    "# create_spectram_plot(loc_raw_dataverse_files,\n",
    "#                      loc_fig_dataverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 05:55:51.371119: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-05-05 05:55:51.371136: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-05-05 05:55:51.371141: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-05-05 05:55:51.371169: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-05 05:55:51.371183: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/wyd2hu/Documents/SA39/ForegroundSpeech/Only_Spectrogram_Figure_Dataverse/fold2_background/0_9754.png', '/Users/wyd2hu/Documents/SA39/ForegroundSpeech/Only_Spectrogram_Figure_Dataverse/fold3_background/0_26156.png']\n"
     ]
    }
   ],
   "source": [
    "list_metrics = [keras.metrics.TruePositives(name='tp'),\n",
    "                keras.metrics.FalsePositives(name='fp'),\n",
    "                keras.metrics.TrueNegatives(name='tn'),\n",
    "                keras.metrics.FalseNegatives(name='fn'),\n",
    "                keras.metrics.F1Score(name='f1_score', threshold=0.5, average='macro'),\n",
    "                keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                keras.metrics.Precision(name='precision'),\n",
    "                keras.metrics.Recall(name='recall'),\n",
    "                keras.metrics.AUC(name='auc')]\n",
    "\n",
    "df_image_path = pd.DataFrame(columns = [str_filename, str_target])\n",
    "loc_dataverse_image = loc_fig_dataverse\n",
    "str_cls_1 = 'Class_1'\n",
    "str_cls_0 = 'Class_0'\n",
    "\n",
    "\n",
    "for fore_or_back_folder in os.listdir(loc_dataverse_image):\n",
    "  if '.DS_Store' not in fore_or_back_folder:\n",
    "    df_temp = pd.DataFrame({str_filename: [os.path.join(loc_dataverse_image, fore_or_back_folder, filename) \n",
    "                                          for filename in os.listdir(os.path.join(loc_dataverse_image, fore_or_back_folder))],\n",
    "                            str_target: np.repeat(str_cls_1 if str_fore in fore_or_back_folder else str_cls_0,\n",
    "                                                  len(os.listdir(os.path.join(loc_dataverse_image, fore_or_back_folder))))})\n",
    "    df_image_path = pd.concat([df_image_path, df_temp])\n",
    "\n",
    "df_image_path = shuffle(df_image_path, random_state=random_state)\n",
    "df_image_path.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(df_image_path.head(2)[str_filename].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Found 71530 validated image filenames belonging to 2 classes.\n",
      "Found 3974 validated image filenames belonging to 2 classes.\n",
      "Found 3974 validated image filenames belonging to 2 classes.\n",
      "2236/2236 [==============================] - 3801s 2s/step - loss: 0.7997 - tp: 6946.0000 - fp: 17471.0000 - tn: 39070.0000 - fn: 22091.0000 - f1_score: 0.2599 - accuracy: 0.5377 - precision: 0.2845 - recall: 0.2392 - auc: 0.4419 - val_loss: 0.6748 - val_tp: 2.0000 - val_fp: 115.0000 - val_tn: 2510.0000 - val_fn: 1347.0000 - val_f1_score: 0.0027 - val_accuracy: 0.6321 - val_precision: 0.0171 - val_recall: 0.0015 - val_auc: 0.3515\n",
      "125/125 [==============================] - 202s 2s/step - loss: 0.6746 - tp: 5.0000 - fp: 112.0000 - tn: 2512.0000 - fn: 1345.0000 - f1_score: 0.0068 - accuracy: 0.6334 - precision: 0.0427 - recall: 0.0037 - auc: 0.3506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Training only the last layers 🙈😡😠\n",
      "Test Performance\n",
      "\n",
      " 0.04273504391312599 0.003703703638166189 0.9573170731707317 0.6333668828010559 0.35060709714889526 0.48051038840444893 \n",
      "\n",
      "\n",
      "\n",
      "Hey, retraining 😍😍😍🤜🤛\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 07:29:39.231640: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2236/2236 [==============================] - 4658s 2s/step - loss: 0.7035 - tp: 17866.0000 - fp: 13333.0000 - tn: 36529.0000 - fn: 7776.0000 - f1_score: 0.6286 - accuracy: 0.7204 - precision: 0.5726 - recall: 0.6967 - auc: 0.7823 - val_loss: 0.4256 - val_tp: 1124.0000 - val_fp: 480.0000 - val_tn: 2145.0000 - val_fn: 225.0000 - val_f1_score: 0.7613 - val_accuracy: 0.8226 - val_precision: 0.7007 - val_recall: 0.8332 - val_auc: 0.9004\n",
      "Epoch 2/25\n",
      "2236/2236 [==============================] - 3826s 2s/step - loss: 0.6871 - tp: 18802.0000 - fp: 11056.0000 - tn: 36182.0000 - fn: 5490.0000 - f1_score: 0.6944 - accuracy: 0.7687 - precision: 0.6297 - recall: 0.7740 - auc: 0.8293 - val_loss: 0.4473 - val_tp: 880.0000 - val_fp: 205.0000 - val_tn: 2420.0000 - val_fn: 469.0000 - val_f1_score: 0.7231 - val_accuracy: 0.8304 - val_precision: 0.8111 - val_recall: 0.6523 - val_auc: 0.9030\n",
      "Epoch 3/25\n",
      "2236/2236 [==============================] - 3794s 2s/step - loss: 0.5305 - tp: 18803.0000 - fp: 10337.0000 - tn: 36901.0000 - fn: 5489.0000 - f1_score: 0.7038 - accuracy: 0.7788 - precision: 0.6453 - recall: 0.7740 - auc: 0.8510 - val_loss: 0.3940 - val_tp: 1112.0000 - val_fp: 406.0000 - val_tn: 2219.0000 - val_fn: 237.0000 - val_f1_score: 0.7757 - val_accuracy: 0.8382 - val_precision: 0.7325 - val_recall: 0.8243 - val_auc: 0.9155\n",
      "Epoch 4/25\n",
      "2236/2236 [==============================] - 3829s 2s/step - loss: 0.4288 - tp: 19234.0000 - fp: 8272.0000 - tn: 38966.0000 - fn: 5058.0000 - f1_score: 0.7427 - accuracy: 0.8136 - precision: 0.6993 - recall: 0.7918 - auc: 0.8868 - val_loss: 0.4065 - val_tp: 1160.0000 - val_fp: 486.0000 - val_tn: 2139.0000 - val_fn: 189.0000 - val_f1_score: 0.7746 - val_accuracy: 0.8301 - val_precision: 0.7047 - val_recall: 0.8599 - val_auc: 0.9194\n",
      "Epoch 5/25\n",
      "2236/2236 [==============================] - 3825s 2s/step - loss: 0.4149 - tp: 19539.0000 - fp: 8074.0000 - tn: 39164.0000 - fn: 4753.0000 - f1_score: 0.7529 - accuracy: 0.8207 - precision: 0.7076 - recall: 0.8043 - auc: 0.8943 - val_loss: 0.3623 - val_tp: 1086.0000 - val_fp: 336.0000 - val_tn: 2289.0000 - val_fn: 263.0000 - val_f1_score: 0.7838 - val_accuracy: 0.8493 - val_precision: 0.7637 - val_recall: 0.8050 - val_auc: 0.9218\n",
      "Epoch 6/25\n",
      "2236/2236 [==============================] - 3796s 2s/step - loss: 0.3997 - tp: 19726.0000 - fp: 7604.0000 - tn: 39634.0000 - fn: 4566.0000 - f1_score: 0.7642 - accuracy: 0.8299 - precision: 0.7218 - recall: 0.8120 - auc: 0.9022 - val_loss: 0.3808 - val_tp: 1152.0000 - val_fp: 451.0000 - val_tn: 2174.0000 - val_fn: 197.0000 - val_f1_score: 0.7805 - val_accuracy: 0.8369 - val_precision: 0.7187 - val_recall: 0.8540 - val_auc: 0.9229\n",
      "Epoch 7/25\n",
      "2236/2236 [==============================] - 3791s 2s/step - loss: 0.4043 - tp: 19788.0000 - fp: 7733.0000 - tn: 39505.0000 - fn: 4504.0000 - f1_score: 0.7638 - accuracy: 0.8289 - precision: 0.7190 - recall: 0.8146 - auc: 0.9010 - val_loss: 0.3417 - val_tp: 1048.0000 - val_fp: 258.0000 - val_tn: 2367.0000 - val_fn: 301.0000 - val_f1_score: 0.7895 - val_accuracy: 0.8593 - val_precision: 0.8025 - val_recall: 0.7769 - val_auc: 0.9267\n",
      "Epoch 8/25\n",
      "2236/2236 [==============================] - 3825s 2s/step - loss: 0.3910 - tp: 19907.0000 - fp: 7404.0000 - tn: 39834.0000 - fn: 4385.0000 - f1_score: 0.7715 - accuracy: 0.8352 - precision: 0.7289 - recall: 0.8195 - auc: 0.9073 - val_loss: 0.3566 - val_tp: 1123.0000 - val_fp: 365.0000 - val_tn: 2260.0000 - val_fn: 226.0000 - val_f1_score: 0.7917 - val_accuracy: 0.8513 - val_precision: 0.7547 - val_recall: 0.8325 - val_auc: 0.9252\n",
      "Epoch 9/25\n",
      "2236/2236 [==============================] - 3809s 2s/step - loss: 0.4304 - tp: 19791.0000 - fp: 8043.0000 - tn: 39195.0000 - fn: 4501.0000 - f1_score: 0.7594 - accuracy: 0.8246 - precision: 0.7110 - recall: 0.8147 - auc: 0.8960 - val_loss: 0.3323 - val_tp: 1041.0000 - val_fp: 253.0000 - val_tn: 2372.0000 - val_fn: 308.0000 - val_f1_score: 0.7877 - val_accuracy: 0.8588 - val_precision: 0.8045 - val_recall: 0.7717 - val_auc: 0.9286\n",
      "Epoch 10/25\n",
      "2236/2236 [==============================] - 3804s 2s/step - loss: 0.3895 - tp: 19984.0000 - fp: 7438.0000 - tn: 39800.0000 - fn: 4308.0000 - f1_score: 0.7729 - accuracy: 0.8358 - precision: 0.7288 - recall: 0.8227 - auc: 0.9086 - val_loss: 0.3418 - val_tp: 1069.0000 - val_fp: 295.0000 - val_tn: 2330.0000 - val_fn: 280.0000 - val_f1_score: 0.7881 - val_accuracy: 0.8553 - val_precision: 0.7837 - val_recall: 0.7924 - val_auc: 0.9289\n",
      "Epoch 11/25\n",
      "2236/2236 [==============================] - 4831s 2s/step - loss: 0.3794 - tp: 20034.0000 - fp: 7257.0000 - tn: 39981.0000 - fn: 4258.0000 - f1_score: 0.7768 - accuracy: 0.8390 - precision: 0.7341 - recall: 0.8247 - auc: 0.9130 - val_loss: 0.3210 - val_tp: 965.0000 - val_fp: 168.0000 - val_tn: 2457.0000 - val_fn: 384.0000 - val_f1_score: 0.7776 - val_accuracy: 0.8611 - val_precision: 0.8517 - val_recall: 0.7153 - val_auc: 0.9309\n",
      "Epoch 12/25\n",
      "2236/2236 [==============================] - 3876s 2s/step - loss: 0.3819 - tp: 19997.0000 - fp: 7224.0000 - tn: 40014.0000 - fn: 4295.0000 - f1_score: 0.7764 - accuracy: 0.8390 - precision: 0.7346 - recall: 0.8232 - auc: 0.9123 - val_loss: 0.3347 - val_tp: 1077.0000 - val_fp: 295.0000 - val_tn: 2330.0000 - val_fn: 272.0000 - val_f1_score: 0.7916 - val_accuracy: 0.8573 - val_precision: 0.7850 - val_recall: 0.7984 - val_auc: 0.9284\n",
      "Epoch 13/25\n",
      "2236/2236 [==============================] - 3897s 2s/step - loss: 0.3758 - tp: 20175.0000 - fp: 7057.0000 - tn: 40181.0000 - fn: 4117.0000 - f1_score: 0.7831 - accuracy: 0.8438 - precision: 0.7409 - recall: 0.8305 - auc: 0.9154 - val_loss: 0.3183 - val_tp: 1006.0000 - val_fp: 193.0000 - val_tn: 2432.0000 - val_fn: 343.0000 - val_f1_score: 0.7896 - val_accuracy: 0.8651 - val_precision: 0.8390 - val_recall: 0.7457 - val_auc: 0.9318\n",
      "Epoch 14/25\n",
      "2236/2236 [==============================] - 3875s 2s/step - loss: 0.3738 - tp: 20108.0000 - fp: 7002.0000 - tn: 40236.0000 - fn: 4184.0000 - f1_score: 0.7824 - accuracy: 0.8436 - precision: 0.7417 - recall: 0.8278 - auc: 0.9163 - val_loss: 0.3329 - val_tp: 1106.0000 - val_fp: 312.0000 - val_tn: 2313.0000 - val_fn: 243.0000 - val_f1_score: 0.7994 - val_accuracy: 0.8603 - val_precision: 0.7800 - val_recall: 0.8199 - val_auc: 0.9304\n",
      "Epoch 15/25\n",
      "2236/2236 [==============================] - 3933s 2s/step - loss: 0.3679 - tp: 20201.0000 - fp: 6923.0000 - tn: 40315.0000 - fn: 4091.0000 - f1_score: 0.7858 - accuracy: 0.8460 - precision: 0.7448 - recall: 0.8316 - auc: 0.9189 - val_loss: 0.3167 - val_tp: 984.0000 - val_fp: 171.0000 - val_tn: 2454.0000 - val_fn: 365.0000 - val_f1_score: 0.7859 - val_accuracy: 0.8651 - val_precision: 0.8519 - val_recall: 0.7294 - val_auc: 0.9312\n",
      "Epoch 16/25\n",
      "2236/2236 [==============================] - 4204s 2s/step - loss: 0.3700 - tp: 20293.0000 - fp: 6947.0000 - tn: 40291.0000 - fn: 3999.0000 - f1_score: 0.7876 - accuracy: 0.8470 - precision: 0.7450 - recall: 0.8354 - auc: 0.9187 - val_loss: 0.3261 - val_tp: 1093.0000 - val_fp: 285.0000 - val_tn: 2340.0000 - val_fn: 256.0000 - val_f1_score: 0.8016 - val_accuracy: 0.8639 - val_precision: 0.7932 - val_recall: 0.8102 - val_auc: 0.9326\n",
      "Epoch 17/25\n",
      "2236/2236 [==============================] - 3892s 2s/step - loss: 0.3725 - tp: 20215.0000 - fp: 6947.0000 - tn: 40291.0000 - fn: 4077.0000 - f1_score: 0.7858 - accuracy: 0.8459 - precision: 0.7442 - recall: 0.8322 - auc: 0.9185 - val_loss: 0.3124 - val_tp: 985.0000 - val_fp: 181.0000 - val_tn: 2444.0000 - val_fn: 364.0000 - val_f1_score: 0.7833 - val_accuracy: 0.8629 - val_precision: 0.8448 - val_recall: 0.7302 - val_auc: 0.9325\n",
      "Epoch 18/25\n",
      "2236/2236 [==============================] - 4120s 2s/step - loss: 0.3862 - tp: 20210.0000 - fp: 7248.0000 - tn: 39990.0000 - fn: 4082.0000 - f1_score: 0.7811 - accuracy: 0.8416 - precision: 0.7360 - recall: 0.8320 - auc: 0.9155 - val_loss: 0.3190 - val_tp: 961.0000 - val_fp: 155.0000 - val_tn: 2470.0000 - val_fn: 388.0000 - val_f1_score: 0.7797 - val_accuracy: 0.8634 - val_precision: 0.8611 - val_recall: 0.7124 - val_auc: 0.9294\n",
      "Epoch 19/25\n",
      "2236/2236 [==============================] - 3811s 2s/step - loss: 0.3646 - tp: 20254.0000 - fp: 6743.0000 - tn: 40495.0000 - fn: 4038.0000 - f1_score: 0.7898 - accuracy: 0.8493 - precision: 0.7502 - recall: 0.8338 - auc: 0.9220 - val_loss: 0.3177 - val_tp: 976.0000 - val_fp: 172.0000 - val_tn: 2453.0000 - val_fn: 373.0000 - val_f1_score: 0.7817 - val_accuracy: 0.8629 - val_precision: 0.8502 - val_recall: 0.7235 - val_auc: 0.9303\n",
      "Epoch 20/25\n",
      "2236/2236 [==============================] - 3959s 2s/step - loss: 0.3664 - tp: 20291.0000 - fp: 6743.0000 - tn: 40495.0000 - fn: 4001.0000 - f1_score: 0.7907 - accuracy: 0.8498 - precision: 0.7506 - recall: 0.8353 - auc: 0.9219 - val_loss: 0.3359 - val_tp: 1123.0000 - val_fp: 321.0000 - val_tn: 2304.0000 - val_fn: 226.0000 - val_f1_score: 0.8042 - val_accuracy: 0.8624 - val_precision: 0.7777 - val_recall: 0.8325 - val_auc: 0.9319\n",
      "Epoch 21/25\n",
      "2236/2236 [==============================] - 4536s 2s/step - loss: 0.3656 - tp: 20309.0000 - fp: 6781.0000 - tn: 40457.0000 - fn: 3983.0000 - f1_score: 0.7905 - accuracy: 0.8495 - precision: 0.7497 - recall: 0.8360 - auc: 0.9224 - val_loss: 0.3214 - val_tp: 1090.0000 - val_fp: 276.0000 - val_tn: 2349.0000 - val_fn: 259.0000 - val_f1_score: 0.8029 - val_accuracy: 0.8654 - val_precision: 0.7980 - val_recall: 0.8080 - val_auc: 0.9324\n",
      "Epoch 22/25\n",
      "2236/2236 [==============================] - 3910s 2s/step - loss: 0.3675 - tp: 20354.0000 - fp: 6868.0000 - tn: 40370.0000 - fn: 3938.0000 - f1_score: 0.7902 - accuracy: 0.8489 - precision: 0.7477 - recall: 0.8379 - auc: 0.9220 - val_loss: 0.3312 - val_tp: 1111.0000 - val_fp: 325.0000 - val_tn: 2300.0000 - val_fn: 238.0000 - val_f1_score: 0.7978 - val_accuracy: 0.8583 - val_precision: 0.7737 - val_recall: 0.8236 - val_auc: 0.9304\n",
      "125/125 [==============================] - 199s 2s/step\n",
      "125/125 [==============================] - 198s 2s/step - loss: 0.3271 - tp: 987.0000 - fp: 199.0000 - tn: 2425.0000 - fn: 363.0000 - f1_score: 0.7784 - accuracy: 0.8586 - precision: 0.8322 - recall: 0.7311 - auc: 0.9236\n",
      "\n",
      "\n",
      "\n",
      " After retrain all layers \n",
      "Test Performance\n",
      "\n",
      " 0.8322091102600098 0.7311111092567444 0.9241615853658537 0.8585807681083679 0.9235974550247192 0.8276363473112991 \n",
      "\n",
      "\n",
      "\n",
      "Found 3974 validated image filenames belonging to 2 classes.\n",
      "Found 3974 validated image filenames belonging to 2 classes.\n",
      "2236/2236 [==============================] - 3861s 2s/step - loss: 0.7415 - tp: 11782.0000 - fp: 22506.0000 - tn: 27356.0000 - fn: 13860.0000 - f1_score: 0.3932 - accuracy: 0.5184 - precision: 0.3436 - recall: 0.4595 - auc: 0.5148 - val_loss: 0.7004 - val_tp: 471.0000 - val_fp: 1394.0000 - val_tn: 1230.0000 - val_fn: 879.0000 - val_f1_score: 0.2930 - val_accuracy: 0.4280 - val_precision: 0.2525 - val_recall: 0.3489 - val_auc: 0.3816\n",
      "125/125 [==============================] - 205s 2s/step - loss: 0.6991 - tp: 535.0000 - fp: 1402.0000 - tn: 1223.0000 - fn: 814.0000 - f1_score: 0.3256 - accuracy: 0.4424 - precision: 0.2762 - recall: 0.3966 - auc: 0.4071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Training only the last layers 🙈😡😠\n",
      "Test Performance\n",
      "\n",
      " 0.2762003242969513 0.39659005403518677 0.4659047619047619 0.44237545132637024 0.4070504307746887 0.4312474079699743 \n",
      "\n",
      "\n",
      "\n",
      "Hey, retraining 😍😍😍🤜🤛\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 09:07:35.788540: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2236/2236 [==============================] - 3859s 2s/step - loss: 1.6953 - tp: 16545.0000 - fp: 15949.0000 - tn: 33914.0000 - fn: 9096.0000 - f1_score: 0.5692 - accuracy: 0.6683 - precision: 0.5092 - recall: 0.6453 - auc: 0.7172 - val_loss: 0.7507 - val_tp: 1319.0000 - val_fp: 1648.0000 - val_tn: 976.0000 - val_fn: 31.0000 - val_f1_score: 0.6111 - val_accuracy: 0.5775 - val_precision: 0.4446 - val_recall: 0.9770 - val_auc: 0.8700\n",
      "Epoch 2/25\n",
      "2236/2236 [==============================] - 3837s 2s/step - loss: 0.5598 - tp: 18253.0000 - fp: 11393.0000 - tn: 35845.0000 - fn: 6039.0000 - f1_score: 0.6768 - accuracy: 0.7563 - precision: 0.6157 - recall: 0.7514 - auc: 0.8276 - val_loss: 0.5823 - val_tp: 1264.0000 - val_fp: 1118.0000 - val_tn: 1506.0000 - val_fn: 86.0000 - val_f1_score: 0.6774 - val_accuracy: 0.6970 - val_precision: 0.5306 - val_recall: 0.9363 - val_auc: 0.8817\n",
      "Epoch 3/25\n",
      "2236/2236 [==============================] - 3832s 2s/step - loss: 0.4833 - tp: 18494.0000 - fp: 10437.0000 - tn: 36801.0000 - fn: 5798.0000 - f1_score: 0.6950 - accuracy: 0.7730 - precision: 0.6392 - recall: 0.7613 - auc: 0.8518 - val_loss: 0.5445 - val_tp: 1237.0000 - val_fp: 945.0000 - val_tn: 1679.0000 - val_fn: 113.0000 - val_f1_score: 0.7005 - val_accuracy: 0.7338 - val_precision: 0.5669 - val_recall: 0.9163 - val_auc: 0.8870\n",
      "Epoch 4/25\n",
      "2236/2236 [==============================] - 3837s 2s/step - loss: 0.5118 - tp: 18710.0000 - fp: 10790.0000 - tn: 36448.0000 - fn: 5582.0000 - f1_score: 0.6956 - accuracy: 0.7711 - precision: 0.6342 - recall: 0.7702 - auc: 0.8474 - val_loss: 0.6236 - val_tp: 1288.0000 - val_fp: 1171.0000 - val_tn: 1453.0000 - val_fn: 62.0000 - val_f1_score: 0.6763 - val_accuracy: 0.6897 - val_precision: 0.5238 - val_recall: 0.9541 - val_auc: 0.8943\n",
      "Epoch 5/25\n",
      "2236/2236 [==============================] - 5145s 2s/step - loss: 0.4521 - tp: 18970.0000 - fp: 9686.0000 - tn: 37552.0000 - fn: 5322.0000 - f1_score: 0.7166 - accuracy: 0.7902 - precision: 0.6620 - recall: 0.7809 - auc: 0.8714 - val_loss: 0.4814 - val_tp: 1204.0000 - val_fp: 750.0000 - val_tn: 1874.0000 - val_fn: 146.0000 - val_f1_score: 0.7288 - val_accuracy: 0.7745 - val_precision: 0.6162 - val_recall: 0.8919 - val_auc: 0.8994\n",
      "Epoch 6/25\n",
      "2236/2236 [==============================] - 4055s 2s/step - loss: 0.4433 - tp: 19128.0000 - fp: 9079.0000 - tn: 38159.0000 - fn: 5164.0000 - f1_score: 0.7287 - accuracy: 0.8009 - precision: 0.6781 - recall: 0.7874 - auc: 0.8777 - val_loss: 0.5181 - val_tp: 1232.0000 - val_fp: 853.0000 - val_tn: 1771.0000 - val_fn: 118.0000 - val_f1_score: 0.7173 - val_accuracy: 0.7557 - val_precision: 0.5909 - val_recall: 0.9126 - val_auc: 0.9021\n",
      "Epoch 7/25\n",
      "2236/2236 [==============================] - 3880s 2s/step - loss: 0.4386 - tp: 19192.0000 - fp: 9040.0000 - tn: 38198.0000 - fn: 5100.0000 - f1_score: 0.7308 - accuracy: 0.8023 - precision: 0.6798 - recall: 0.7901 - auc: 0.8805 - val_loss: 0.5041 - val_tp: 1252.0000 - val_fp: 838.0000 - val_tn: 1786.0000 - val_fn: 98.0000 - val_f1_score: 0.7279 - val_accuracy: 0.7645 - val_precision: 0.5990 - val_recall: 0.9274 - val_auc: 0.9085\n",
      "Epoch 8/25\n",
      "2236/2236 [==============================] - 3882s 2s/step - loss: 0.4245 - tp: 19400.0000 - fp: 8713.0000 - tn: 38525.0000 - fn: 4892.0000 - f1_score: 0.7404 - accuracy: 0.8098 - precision: 0.6901 - recall: 0.7986 - auc: 0.8885 - val_loss: 0.5174 - val_tp: 1265.0000 - val_fp: 899.0000 - val_tn: 1725.0000 - val_fn: 85.0000 - val_f1_score: 0.7200 - val_accuracy: 0.7524 - val_precision: 0.5846 - val_recall: 0.9370 - val_auc: 0.9099\n",
      "Epoch 9/25\n",
      "2236/2236 [==============================] - 3876s 2s/step - loss: 0.4260 - tp: 19399.0000 - fp: 8696.0000 - tn: 38542.0000 - fn: 4893.0000 - f1_score: 0.7406 - accuracy: 0.8100 - precision: 0.6905 - recall: 0.7986 - auc: 0.8887 - val_loss: 0.4289 - val_tp: 1184.0000 - val_fp: 579.0000 - val_tn: 2045.0000 - val_fn: 166.0000 - val_f1_score: 0.7607 - val_accuracy: 0.8125 - val_precision: 0.6716 - val_recall: 0.8770 - val_auc: 0.9139\n",
      "Epoch 10/25\n",
      "2236/2236 [==============================] - 4011s 2s/step - loss: 0.4185 - tp: 19481.0000 - fp: 8476.0000 - tn: 38762.0000 - fn: 4811.0000 - f1_score: 0.7457 - accuracy: 0.8142 - precision: 0.6968 - recall: 0.8020 - auc: 0.8927 - val_loss: 0.4342 - val_tp: 1203.0000 - val_fp: 626.0000 - val_tn: 1998.0000 - val_fn: 147.0000 - val_f1_score: 0.7568 - val_accuracy: 0.8055 - val_precision: 0.6577 - val_recall: 0.8911 - val_auc: 0.9129\n",
      "Epoch 11/25\n",
      "2236/2236 [==============================] - 4076s 2s/step - loss: 0.4149 - tp: 19530.0000 - fp: 8275.0000 - tn: 38963.0000 - fn: 4762.0000 - f1_score: 0.7498 - accuracy: 0.8177 - precision: 0.7024 - recall: 0.8040 - auc: 0.8946 - val_loss: 0.4241 - val_tp: 1196.0000 - val_fp: 581.0000 - val_tn: 2043.0000 - val_fn: 154.0000 - val_f1_score: 0.7650 - val_accuracy: 0.8150 - val_precision: 0.6730 - val_recall: 0.8859 - val_auc: 0.9171\n",
      "Epoch 12/25\n",
      "2236/2236 [==============================] - 4617s 2s/step - loss: 0.5148 - tp: 19396.0000 - fp: 9054.0000 - tn: 38184.0000 - fn: 4896.0000 - f1_score: 0.7355 - accuracy: 0.8050 - precision: 0.6818 - recall: 0.7985 - auc: 0.8735 - val_loss: 0.4715 - val_tp: 1190.0000 - val_fp: 620.0000 - val_tn: 2004.0000 - val_fn: 160.0000 - val_f1_score: 0.7532 - val_accuracy: 0.8037 - val_precision: 0.6575 - val_recall: 0.8815 - val_auc: 0.9098\n",
      "Epoch 13/25\n",
      "2236/2236 [==============================] - 4158s 2s/step - loss: 0.5412 - tp: 19384.0000 - fp: 8956.0000 - tn: 38282.0000 - fn: 4908.0000 - f1_score: 0.7366 - accuracy: 0.8062 - precision: 0.6840 - recall: 0.7980 - auc: 0.8785 - val_loss: 0.3718 - val_tp: 1111.0000 - val_fp: 417.0000 - val_tn: 2207.0000 - val_fn: 239.0000 - val_f1_score: 0.7721 - val_accuracy: 0.8349 - val_precision: 0.7271 - val_recall: 0.8230 - val_auc: 0.9180\n",
      "Epoch 14/25\n",
      "2236/2236 [==============================] - 3967s 2s/step - loss: 0.4289 - tp: 19757.0000 - fp: 8146.0000 - tn: 39092.0000 - fn: 4535.0000 - f1_score: 0.7570 - accuracy: 0.8227 - precision: 0.7081 - recall: 0.8133 - auc: 0.8994 - val_loss: 0.4676 - val_tp: 1247.0000 - val_fp: 728.0000 - val_tn: 1896.0000 - val_fn: 103.0000 - val_f1_score: 0.7501 - val_accuracy: 0.7909 - val_precision: 0.6314 - val_recall: 0.9237 - val_auc: 0.9202\n",
      "Epoch 15/25\n",
      "2236/2236 [==============================] - 3967s 2s/step - loss: 0.4390 - tp: 19680.0000 - fp: 8299.0000 - tn: 38939.0000 - fn: 4612.0000 - f1_score: 0.7530 - accuracy: 0.8195 - precision: 0.7034 - recall: 0.8101 - auc: 0.8970 - val_loss: 0.3897 - val_tp: 1167.0000 - val_fp: 471.0000 - val_tn: 2153.0000 - val_fn: 183.0000 - val_f1_score: 0.7811 - val_accuracy: 0.8354 - val_precision: 0.7125 - val_recall: 0.8644 - val_auc: 0.9208\n",
      "Epoch 16/25\n",
      "2236/2236 [==============================] - 3949s 2s/step - loss: 0.4387 - tp: 19697.0000 - fp: 8347.0000 - tn: 38891.0000 - fn: 4595.0000 - f1_score: 0.7527 - accuracy: 0.8191 - precision: 0.7024 - recall: 0.8108 - auc: 0.8970 - val_loss: 0.4546 - val_tp: 1226.0000 - val_fp: 660.0000 - val_tn: 1964.0000 - val_fn: 124.0000 - val_f1_score: 0.7577 - val_accuracy: 0.8027 - val_precision: 0.6501 - val_recall: 0.9081 - val_auc: 0.9199\n",
      "Epoch 17/25\n",
      "2236/2236 [==============================] - 3917s 2s/step - loss: 0.4440 - tp: 19727.0000 - fp: 8237.0000 - tn: 39001.0000 - fn: 4565.0000 - f1_score: 0.7550 - accuracy: 0.8210 - precision: 0.7054 - recall: 0.8121 - auc: 0.8973 - val_loss: 0.4407 - val_tp: 1213.0000 - val_fp: 629.0000 - val_tn: 1995.0000 - val_fn: 137.0000 - val_f1_score: 0.7600 - val_accuracy: 0.8072 - val_precision: 0.6585 - val_recall: 0.8985 - val_auc: 0.9195\n",
      "Epoch 18/25\n",
      "2236/2236 [==============================] - 3856s 2s/step - loss: 0.4597 - tp: 19705.0000 - fp: 8454.0000 - tn: 38784.0000 - fn: 4587.0000 - f1_score: 0.7514 - accuracy: 0.8177 - precision: 0.6998 - recall: 0.8112 - auc: 0.8947 - val_loss: 0.3803 - val_tp: 1143.0000 - val_fp: 452.0000 - val_tn: 2172.0000 - val_fn: 207.0000 - val_f1_score: 0.7762 - val_accuracy: 0.8342 - val_precision: 0.7166 - val_recall: 0.8467 - val_auc: 0.9211\n",
      "125/125 [==============================] - 197s 2s/step\n",
      "125/125 [==============================] - 196s 2s/step - loss: 0.3526 - tp: 1129.0000 - fp: 380.0000 - tn: 2245.0000 - fn: 220.0000 - f1_score: 0.7901 - accuracy: 0.8490 - precision: 0.7482 - recall: 0.8369 - auc: 0.9283\n",
      "\n",
      "\n",
      "\n",
      " After retrain all layers \n",
      "Test Performance\n",
      "\n",
      " 0.7481775879859924 0.8369162082672119 0.8552380952380952 0.8490186333656311 0.9283145666122437 0.8460771517526535 \n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Found 71530 validated image filenames belonging to 2 classes.\n",
      "Found 3974 validated image filenames belonging to 2 classes.\n",
      "Found 3974 validated image filenames belonging to 2 classes.\n",
      "2236/2236 [==============================] - 3851s 2s/step - loss: 0.7587 - tp: 22241.0000 - fp: 41579.0000 - tn: 8284.0000 - fn: 3400.0000 - f1_score: 0.4972 - accuracy: 0.4043 - precision: 0.3485 - recall: 0.8674 - auc: 0.5309 - val_loss: 0.7679 - val_tp: 1349.0000 - val_fp: 2625.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_f1_score: 0.5069 - val_accuracy: 0.3395 - val_precision: 0.3395 - val_recall: 1.0000 - val_auc: 0.5099\n",
      "125/125 [==============================] - 201s 2s/step - loss: 0.7679 - tp: 1350.0000 - fp: 2624.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - f1_score: 0.5071 - accuracy: 0.3397 - precision: 0.3397 - recall: 1.0000 - auc: 0.5115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Training only the last layers 🙈😡😠\n",
      "Test Performance\n",
      "\n",
      " 0.3397080898284912 1.0 0.0 0.3397080898284912 0.5115448832511902 0.5 \n",
      "\n",
      "\n",
      "\n",
      "Hey, retraining 😍😍😍🤜🤛\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 06:33:51.673821: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2236/2236 [==============================] - 3931s 2s/step - loss: 0.9793 - tp: 19032.0000 - fp: 16305.0000 - tn: 33557.0000 - fn: 6610.0000 - f1_score: 0.6242 - accuracy: 0.6965 - precision: 0.5386 - recall: 0.7422 - auc: 0.7682 - val_loss: 0.4158 - val_tp: 1012.0000 - val_fp: 372.0000 - val_tn: 2253.0000 - val_fn: 337.0000 - val_f1_score: 0.7406 - val_accuracy: 0.8216 - val_precision: 0.7312 - val_recall: 0.7502 - val_auc: 0.8861\n",
      "Epoch 2/25\n",
      " 398/2236 [====>.........................] - ETA: 1:53:21 - loss: 0.4811 - tp: 3382.0000 - fp: 1747.0000 - tn: 6610.0000 - fn: 997.0000 - f1_score: 0.7114 - accuracy: 0.7845 - precision: 0.6594 - recall: 0.7723 - auc: 0.8589"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 175\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m After retrain all layers \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Performance\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,dict_predict_test\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m), dict_predict_test\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    172\u001b[0m                     specificity, dict_predict_test\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m), dict_predict_test\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m), (specificity \u001b[38;5;241m+\u001b[39m dict_predict_test\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m \u001b[43mtune_resnet_model_for_dataverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 157\u001b[0m, in \u001b[0;36mtune_resnet_model_for_dataverse\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m) \u001b[38;5;66;03m# the default lr is 1e-3\u001b[39;00m\n\u001b[1;32m    153\u001b[0m model_B_on_A\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    154\u001b[0m                     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m    155\u001b[0m                     metrics\u001b[38;5;241m=\u001b[39mlist_metrics)\n\u001b[0;32m--> 157\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_B_on_A\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_epoch_retraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m all_predicted_proba\u001b[38;5;241m.\u001b[39mextend([arr[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(model_B_on_A\u001b[38;5;241m.\u001b[39mpredict(test_gen))])\n\u001b[1;32m    165\u001b[0m all_list_actual_class\u001b[38;5;241m.\u001b[39mextend(pd_data[pd_data[str_fold] \u001b[38;5;241m==\u001b[39m test_fold][str_target]\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def tune_resnet_model_for_dataverse():\n",
    "  global  all_list_actual_class, all_predicted_proba\n",
    "  \n",
    "  all_list_actual_class = [] \n",
    "  all_predicted_proba = []\n",
    "\n",
    "  image_size = 224\n",
    "  input_size = 224\n",
    "  img_width, img_height = 224, 224\n",
    "  \n",
    "\n",
    "  validation_ratio = 0.10\n",
    "  test_ratio = 0.10\n",
    "\n",
    "  n_epoch_for_bias = 1\n",
    "  n_epoch_retraining = 25\n",
    "  batch_size = 32\n",
    "\n",
    "  skf = StratifiedKFold(n_splits=10, shuffle=True, random_state = random_state)\n",
    "\n",
    "  for ith_fold, (train_index, test_index) in enumerate(skf.split(df_image_path[str_filename], df_image_path[str_target])):\n",
    "      print(ith_fold)\n",
    "      if ith_fold < 2:\n",
    "          ################################# Handling Training Data ################################\n",
    "          x_train = df_image_path.iloc[train_index][str_filename].tolist()\n",
    "          y_train = df_image_path.iloc[train_index][str_target].tolist()\n",
    "    \n",
    "          df_temp_train = pd.DataFrame({str_filename: x_train, str_target: y_train})\n",
    "          df_temp_train[str_fold] = np.repeat(1, df_temp_train.shape[0]) # 1 is used (randomly) to denote the train fold everywhere\n",
    "          df_temp_train = shuffle(df_temp_train, random_state=random_state)\n",
    "          df_temp_train.reset_index(inplace=True, drop=True)\n",
    "          \n",
    "          train_gen = ImageDataGenerator(samplewise_center = True,\n",
    "                                        samplewise_std_normalization = True).flow_from_dataframe(\n",
    "                                        dataframe = df_temp_train,\n",
    "                                        x_col = str_filename,\n",
    "                                        y_col = str_target,\n",
    "                                        directory = loc_dataverse_image,\n",
    "                                        target_size = (image_size, image_size),\n",
    "                                        class_mode = 'binary',\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = True)\n",
    "          classes = df_temp_train[str_target].str.replace('Class_', '').astype(np.int16)\n",
    "          neg, pos = np.bincount(classes)\n",
    "          total = neg + pos\n",
    "          weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "          weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "          class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "    \n",
    "          ################################ Validation and Test data ################################\n",
    "          x_test = df_image_path.iloc[test_index][str_filename].tolist()\n",
    "          y_test = df_image_path.iloc[test_index][str_target].tolist()\n",
    "    \n",
    "          x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size = test_ratio / (test_ratio + validation_ratio),\n",
    "                                                          shuffle=True, stratify = y_test, random_state = random_state)\n",
    "          df_temp_val = pd.DataFrame({str_filename: x_val, str_target: y_val})\n",
    "          df_temp_val[str_fold] = np.repeat(2, df_temp_val.shape[0])\n",
    "    \n",
    "          df_temp_test = pd.DataFrame({str_filename: x_test, str_target: y_test})\n",
    "          df_temp_test[str_fold] = np.repeat(3, df_temp_test.shape[0])\n",
    "    \n",
    "          pd_data = pd.concat([df_temp_train, df_temp_val, df_temp_test])\n",
    "          \n",
    "          ################################ Image Data Generator ################################\n",
    "          for train_fold, val_fold, test_fold in ((1, 2, 3), (1, 3, 2)):\n",
    "            val_gen = ImageDataGenerator(samplewise_center=True,\n",
    "                                          samplewise_std_normalization=True).flow_from_dataframe(\n",
    "                                          dataframe=pd_data[pd_data[str_fold] == val_fold],\n",
    "                                          x_col = str_filename,\n",
    "                                          y_col = str_target,\n",
    "                                          directory = loc_dataverse_image,\n",
    "                                          target_size = (image_size, image_size),\n",
    "                                          class_mode ='binary',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=True)\n",
    "    \n",
    "            test_gen = ImageDataGenerator(samplewise_center=True,\n",
    "                                          samplewise_std_normalization=True).flow_from_dataframe(\n",
    "                                          dataframe=pd_data[pd_data[str_fold] == test_fold],\n",
    "                                          x_col = str_filename,\n",
    "                                          y_col = str_target,\n",
    "                                          directory=loc_dataverse_image,\n",
    "                                          target_size=(image_size, image_size),\n",
    "                                          class_mode='binary',\n",
    "                                          batch_size= batch_size,\n",
    "                                          shuffle=True)\n",
    "    \n",
    "            ###################### Model training (For bias in the last layer) ######################\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                input_shape = (3, img_width, img_height)\n",
    "            else:\n",
    "                input_shape = (img_width, img_height, 3)\n",
    "    \n",
    "            resnet_model = ResNet50(include_top=False, weights='imagenet')\n",
    "    \n",
    "            # Create a new Sequential model and add the ResNet50 model as a layer\n",
    "            keras_ResNet_model = tf.keras.Sequential([resnet_model])\n",
    "    \n",
    "            model_B_on_A = keras.models.Sequential(keras_ResNet_model.layers[:-1])\n",
    "    \n",
    "            model_B_on_A.add(keras.layers.Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "            model_B_on_A.add(keras.layers.Activation('relu'))\n",
    "            model_B_on_A.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "            model_B_on_A.add(keras.layers.Conv2D(32, (3, 3)))\n",
    "            model_B_on_A.add(keras.layers.Activation('relu'))\n",
    "            model_B_on_A.add(keras.layers.Dropout(0.1))\n",
    "            model_B_on_A.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "            model_B_on_A.add(keras.layers.Conv2D(64, (3, 3)))\n",
    "            model_B_on_A.add(keras.layers.Activation('relu'))\n",
    "            model_B_on_A.add(keras.layers.Dropout(0.2))\n",
    "            model_B_on_A.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "            model_B_on_A.add(keras.layers.Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "            model_B_on_A.add(keras.layers.Dense(64))\n",
    "            model_B_on_A.add(keras.layers.Activation('relu'))\n",
    "            model_B_on_A.add(keras.layers.Dropout(0.5))\n",
    "            model_B_on_A.add(keras.layers.Dense(1))\n",
    "            model_B_on_A.add(keras.layers.Activation('sigmoid'))\n",
    "    \n",
    "            for layer in model_B_on_A.layers[:-1]:\n",
    "              layer.trainable = False\n",
    "            \n",
    "            # from tensorflow.keras.optimizers.legacy import Adam\n",
    "            \n",
    "            optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.999) # the default lr is 1e-3\n",
    "            callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "            model_B_on_A.compile(loss='binary_crossentropy',\n",
    "                                optimizer=optimizer,\n",
    "                                metrics=list_metrics)\n",
    "    \n",
    "            history = model_B_on_A.fit(train_gen,\n",
    "                                      epochs = n_epoch_for_bias,\n",
    "                                      validation_data = val_gen,\n",
    "                                      callbacks = callback,\n",
    "                                      class_weight = class_weight,\n",
    "                                      verbose = 1)\n",
    "            \n",
    "            dict_predict_test = model_B_on_A.evaluate(test_gen, return_dict=True)\n",
    "            specificity = dict_predict_test.get('tn')/(dict_predict_test.get('tn') + dict_predict_test.get('fp'))\n",
    "            print('\\n\\n\\n Training only the last layers 🙈😡😠')\n",
    "            print('Test Performance\\n\\n', dict_predict_test.get('precision'), dict_predict_test.get('recall'), specificity,\n",
    "                    dict_predict_test.get('accuracy'), dict_predict_test.get('auc'), (specificity + dict_predict_test.get('recall'))/2, '\\n\\n\\n')\n",
    "    \n",
    "            ###################### Re-training all layers ######################\n",
    "            print('Hey, retraining 😍😍😍🤜🤛')\n",
    "            for layer in model_B_on_A.layers[:-1]:\n",
    "                layer.trainable = True\n",
    "    \n",
    "            optimizer = keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999) # the default lr is 1e-3\n",
    "            model_B_on_A.compile(loss='binary_crossentropy',\n",
    "                                optimizer=optimizer,\n",
    "                                metrics=list_metrics)\n",
    "    \n",
    "            history = model_B_on_A.fit(train_gen,\n",
    "                                      epochs = n_epoch_retraining,\n",
    "                                      validation_data=val_gen,\n",
    "                                      callbacks = callback,\n",
    "                                      class_weight=class_weight,\n",
    "                                      verbose = 1)\n",
    "    \n",
    "            all_predicted_proba.extend([arr[0] for arr in list(model_B_on_A.predict(test_gen))])\n",
    "            all_list_actual_class.extend(pd_data[pd_data[str_fold] == test_fold][str_target].tolist())\n",
    "    \n",
    "            dict_predict_test = model_B_on_A.evaluate(test_gen, return_dict=True)\n",
    "            specificity = dict_predict_test.get('tn')/(dict_predict_test.get('tn') + dict_predict_test.get('fp'))\n",
    "            \n",
    "            print('\\n\\n\\n After retrain all layers ')\n",
    "            print('Test Performance\\n\\n',dict_predict_test.get('precision'), dict_predict_test.get('recall'),\n",
    "                    specificity, dict_predict_test.get('accuracy'), dict_predict_test.get('auc'), (specificity + dict_predict_test.get('recall'))/2, '\\n\\n\\n')\n",
    "            \n",
    "\n",
    "tune_resnet_model_for_dataverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPU, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 04:40:50.618340: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-05-05 04:40:50.618365: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-05-05 04:40:50.618372: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-05-05 04:40:50.618441: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-05 04:40:50.618468: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Create 2 virtual GPUs with 1GB memory each\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024),\n",
    "         tf.config.LogicalDeviceConfiguration(memory_limit=1024),\n",
    "         tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Load the ResNet50 model without the top (classification) layer\n",
    "resnet_model = ResNet50(include_top=False, weights='imagenet')\n",
    "\n",
    "# Create a new Sequential model and add the ResNet50 model as a layer\n",
    "keras_ResNet_model = tf.keras.Sequential([resnet_model])\n",
    "\n",
    "# Optionally, you can add additional layers to the Sequential model here\n",
    "# For example:\n",
    "# keras_ResNet_model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Compile and train the model as needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_fn = getattr(tf.keras, \"version\", None)\n",
    "if version_fn and version_fn().startswith(\"3.\"):\n",
    "  import tf_keras as keras\n",
    "else:\n",
    "  keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_predicted_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_arrays = [np.array([0.42610288], dtype=np.float32), np.array([0.41446418])]\n",
    "\n",
    "# Extract values from each array\n",
    "values = [arr[0] for arr in result_arrays]\n",
    "\n",
    "print(values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation Theater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "str_fore = 'foreground'\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "loc_raw_dataverse_files = '/Users/wyd2hu/Documents/SA39/ForegroundSpeech/dataverse_files/'\n",
    "loc_fig_dataverse = '/Users/wyd2hu/Documents/SA39/ForegroundSpeech/Only_Spectrogram_Figure_Dataverse/' \n",
    "# '/Users/wyd2hu/Documents/SA39/ForegroundSpeech/Figure_Datverse/'\n",
    "\n",
    "def create_spectrogram(file_name, loc_fig):\n",
    "    n_row = 1\n",
    "    n_col = 1\n",
    "    fig, axs = plt.subplots(n_col, n_row, figsize=(20, 20))\n",
    "\n",
    "    signal, sr = librosa.load(file_name)\n",
    "    N_FFT = int(sr * 0.025)\n",
    "    HOP_LENGTH = int(sr * 0.0125)\n",
    "\n",
    "    stft = librosa.stft(signal, n_fft = N_FFT, hop_length = HOP_LENGTH)\n",
    "    \n",
    "    librosa.display.specshow(librosa.amplitude_to_db(stft, ref=np.max), \n",
    "                            y_axis='log', x_axis='time', ax=axs)\n",
    "    \n",
    "    axs.xaxis.label.set_visible(False)\n",
    "    axs.yaxis.label.set_visible(False)\n",
    "    axs.set_xticklabels([])\n",
    "    axs.set_yticklabels([])\n",
    "    \n",
    "    fig.savefig(loc_fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_spectram_plot(loc_data_folder, loc_fig_folder):\n",
    "  n_file_processing = 0\n",
    "\n",
    "  for class_folder in sorted(os.listdir(loc_data_folder)):\n",
    "    if 'DS_Store' not in class_folder:\n",
    "      if not os.path.isdir(os.path.join(loc_fig_folder, class_folder)):\n",
    "        os.mkdir(os.path.join(loc_fig_folder, class_folder))\n",
    "\n",
    "      for file_name in sorted(os.listdir(os.path.join(loc_data_folder, class_folder))):\n",
    "        if file_name.endswith('.wav'):   \n",
    "            try:\n",
    "                loc_fig = os.path.join(loc_fig_folder, class_folder, file_name.replace('wav', 'png'))\n",
    "                # print(loc_fig)\n",
    "                img = Image.open(loc_fig)\n",
    "                img.verify()\n",
    "            except Exception as e:\n",
    "                print('Bad file:', class_folder, os.path.basename(loc_fig))\n",
    "                os.remove(loc_fig)\n",
    "                create_spectrogram(os.path.join(loc_data_folder, class_folder, file_name), loc_fig)\n",
    "\n",
    "        # n_file_processing += 1\n",
    "        # print(n_file_processing, class_folder, os.path.basename(loc_data_folder))\n",
    "\n",
    "create_spectram_plot(loc_raw_dataverse_files,\n",
    "                     loc_fig_dataverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done1\n"
     ]
    }
   ],
   "source": [
    "print(\"Done1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
